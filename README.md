# RAG Document Q&A

A robust Retrieval-Augmented Generation (RAG) document Q&A system leveraging the power of **Llama** models and **Hugging Face embeddings**.

## ğŸš€ Features

- Implements **RAG architecture** for enhanced answer retrieval.
- Uses **Llama model** for generating accurate and contextual responses.
- Employs **Hugging Face embeddings** for efficient document retrieval.
- Built with **LangChain** for seamless orchestration of retrieval and generation.
- Deployed on **Streamlit** for an interactive user interface.

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```sh
git clone https://github.com/KrishBhimani/RAG-Document-Q-A.git
```

### 2ï¸âƒ£ Create a Virtual Environment

#### For Windows:
```sh
python -m venv venv
venv\Scripts\activate
```

#### For macOS/Linux:
```sh
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in the project root and add:

```ini
LANGCHAIN_API_KEY="your_api_key"
HF_TOKEN="your_api_key_here"
LANGCHAIN_PROJECT="your_project_name_here"
GROQ_API_KEY="your_api_key"
```

Ensure `.env` is excluded from version control by adding it to `.gitignore`.

### 5ï¸âƒ£ Run the Streamlit App

```sh
streamlit run app.py
```

## ğŸš€ Deployment on Streamlit Cloud

1. Push the project to GitHub.
2. Go to [Streamlit Cloud](https://share.streamlit.io/).
3. Connect your GitHub repository and select the branch.
4. Add secrets in **Streamlit Settings > Secrets**:
   ```ini
   HUGGINGFACE_API_KEY="your_api_key_here"
   LANGCHAIN_PROJECT="your_project_name_here"
   ```
5. Deploy the app and access it online!

### ğŸŒ Live Demo

Access the deployed app here: **[Streamlit App](https://your-streamlit-app-link)**

